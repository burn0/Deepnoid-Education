{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WGAN_keras_bykim.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMrjakXooI5MbGIdy6XeZ8G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/burn0/Deepnoid-Education/blob/main/WGAN_keras_bykim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AN0M1KV2cAL"
      },
      "source": [
        "# **Source code :**\r\n",
        "\r\n",
        "J. Brownlee, \"How to Develop a Wasserstein Generative Adversarial Network (WGAN) From Scratch,\" Machine Learning Mastery, 2019\r\n",
        "\r\n",
        "https://machinelearningmastery.com/how-to-code-a-wasserstein-generative-adversarial-network-wgan-from-scratch/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwQo-c2B6ZqW"
      },
      "source": [
        "# **Purpose**\r\n",
        "\r\n",
        "WGAN을 이용하여 MNIST 데이터 (숫자 손글씨)를 생성해봅시다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSQFEXth1_wb"
      },
      "source": [
        "# **1. Module import**\r\n",
        "코드 실행에 필요한 module을 import 합니다.\r\n",
        "\r\n",
        "만약, 본인이 코드를 수정할 때 필요로 하는 모듈이 있다면 추가해주시면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CAPqayLKR8j"
      },
      "source": [
        "from numpy import expand_dims\r\n",
        "from numpy import mean\r\n",
        "from numpy import ones\r\n",
        "from numpy.random import randn\r\n",
        "from numpy.random import randint\r\n",
        "from keras.datasets.mnist import load_data\r\n",
        "from keras import backend\r\n",
        "from keras.optimizers import RMSprop\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.layers import Reshape\r\n",
        "from keras.layers import Flatten\r\n",
        "from keras.layers import Conv2D\r\n",
        "from keras.layers import Conv2DTranspose\r\n",
        "from keras.layers import LeakyReLU\r\n",
        "from keras.layers import BatchNormalization\r\n",
        "from keras.initializers import RandomNormal\r\n",
        "from keras.constraints import Constraint\r\n",
        "from matplotlib import pyplot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLYt83MY5HH5"
      },
      "source": [
        "# **2. Weight clipping**\r\n",
        "\r\n",
        "WGAN의 특징 중 하나인 weight clipping을 define 해줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pw3QTXVLKnqH"
      },
      "source": [
        "# clip model weights to a given hypercube\r\n",
        "class ClipConstraint(Constraint):\r\n",
        "\t# set clip value when initialized\r\n",
        "\tdef __init__(self, clip_value):\r\n",
        "\t\tself.clip_value = clip_value\r\n",
        " \r\n",
        "\t# clip model weights to hypercube\r\n",
        "\tdef __call__(self, weights):\r\n",
        "\t\treturn backend.clip(weights, -self.clip_value, self.clip_value)\r\n",
        " \r\n",
        "\t# get the config\r\n",
        "\tdef get_config(self):\r\n",
        "\t\treturn {'clip_value': self.clip_value}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPhfXms75qRp"
      },
      "source": [
        "# **3. Wasserstein loss**\r\n",
        "\r\n",
        "원 논문의 저자는 Pytorch로 해당 loss를 구현했습니다.\r\n",
        "\r\n",
        "Keras에서는 아래 코드와 같이 Wasserstein loss를 구현할 수 있습니다.\r\n",
        "\r\n",
        "Keras에 내장되어 있는 loss가 아닌 customized loss를 사용하고 싶을 때는 아래와 같이 loss를 define 해준 후 model compile 할때 loss 부분에 기입하면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWIFIy1YKwzS"
      },
      "source": [
        "# calculate wasserstein loss\r\n",
        "def wasserstein_loss(y_true, y_pred):\r\n",
        "\treturn backend.mean(y_true * y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cax4LWHG6zaV"
      },
      "source": [
        "# **4. Critic model**\r\n",
        "\r\n",
        "Critic으로 사용할 network를 구성해봅시다.\r\n",
        "\r\n",
        "2개의 convolution layer 에서는 weight clipping을 적용했습니다.\r\n",
        "\r\n",
        "Optimizer는 강의에서 말씀드렸다시피 RMSProp를 사용하였습니다.\r\n",
        "\r\n",
        "Learning rate는 비교적 작은 값으로 설정합니다.\r\n",
        "\r\n",
        "model을 compile 할때, loss는 미리 define한 wasserstein loss를 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDEwPY7cKzo2"
      },
      "source": [
        "# define the standalone critic model\r\n",
        "def define_critic(in_shape=(28,28,1)):\r\n",
        "\t# weight initialization\r\n",
        "\tinit = RandomNormal(stddev=0.02)\r\n",
        "\t# weight constraint\r\n",
        "\tconst = ClipConstraint(0.01)\r\n",
        "\t# define model\r\n",
        "\tmodel = Sequential()\r\n",
        "\t# downsample to 14x14\r\n",
        "\tmodel.add(Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init, kernel_constraint=const, input_shape=in_shape))\r\n",
        "\tmodel.add(BatchNormalization())\r\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\r\n",
        "\t# downsample to 7x7\r\n",
        "\tmodel.add(Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init, kernel_constraint=const))\r\n",
        "\tmodel.add(BatchNormalization())\r\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\r\n",
        "\t# scoring, linear activation\r\n",
        "\tmodel.add(Flatten())\r\n",
        "\tmodel.add(Dense(1))\r\n",
        "\t# compile model\r\n",
        "\topt = RMSprop(lr=0.00005)\r\n",
        "\tmodel.compile(loss=wasserstein_loss, optimizer=opt)\r\n",
        "\treturn model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFh6d9d-tIQV"
      },
      "source": [
        "# **5. Generator model**\r\n",
        "\r\n",
        "1개의 fully-connected layer와 3개의 convolution layer로 구성된 간단한 network를 통해 generator를 구성해봅시다.\r\n",
        "\r\n",
        "Output layer를 제외한 나머지 layer에서는 leakyReLU activation function을 사용하였으며, 2개의 convolution layer에서는 batch normalization을 적용하였습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_k_0CuYK2GV"
      },
      "source": [
        "# define the standalone generator model\r\n",
        "def define_generator(latent_dim):\r\n",
        "\t# weight initialization\r\n",
        "\tinit = RandomNormal(stddev=0.02)\r\n",
        "\t# define model\r\n",
        "\tmodel = Sequential()\r\n",
        "\t# foundation for 7x7 image\r\n",
        "\tn_nodes = 128 * 7 * 7\r\n",
        "\tmodel.add(Dense(n_nodes, kernel_initializer=init, input_dim=latent_dim))\r\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\r\n",
        "\tmodel.add(Reshape((7, 7, 128)))\r\n",
        "\t# upsample to 14x14\r\n",
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\r\n",
        "\tmodel.add(BatchNormalization())\r\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\r\n",
        "\t# upsample to 28x28\r\n",
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\r\n",
        "\tmodel.add(BatchNormalization())\r\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\r\n",
        "\t# output 28x28x1\r\n",
        "\tmodel.add(Conv2D(1, (7,7), activation='tanh', padding='same', kernel_initializer=init))\r\n",
        "\treturn model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdzW8P-fuWSf"
      },
      "source": [
        "# **6. GAN model**\r\n",
        "\r\n",
        "GAN을 이용한 학습이후 최종적으로 사용하게 되는 model은 generator 부분입니다.\r\n",
        "\r\n",
        "Generator는 critic의 영향을 받아 학습을 수행하기 때문에 아래와 같이 define 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaRvO1K5K4cG"
      },
      "source": [
        "# define the combined generator and critic model, for updating the generator\r\n",
        "def define_gan(generator, critic):\r\n",
        "\t# make weights in the critic not trainable\r\n",
        "\tfor layer in critic.layers:\r\n",
        "\t\tif not isinstance(layer, BatchNormalization):\r\n",
        "\t\t\tlayer.trainable = False\r\n",
        "\t# connect them\r\n",
        "\tmodel = Sequential()\r\n",
        "\t# add generator\r\n",
        "\tmodel.add(generator)\r\n",
        "\t# add the critic\r\n",
        "\tmodel.add(critic)\r\n",
        "\t# compile model\r\n",
        "\topt = RMSprop(lr=0.00005)\r\n",
        "\tmodel.compile(loss=wasserstein_loss, optimizer=opt)\r\n",
        "\treturn model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tH4KW9A1vlFr"
      },
      "source": [
        "# **7. Data prepare**\r\n",
        "\r\n",
        "대표적인 public dataset MNIST dataset을 불러옵니다.\r\n",
        "\r\n",
        "0에서 9까지 손글씨 데이터 중 맘에드는 숫자를 골라 불러와봅시다.\r\n",
        "\r\n",
        "각 영상의 Min, Max value를 generator의 output과 동일하게 -1 ~ +1 로 rescaling 해줍니다.\r\n",
        "\r\n",
        "Random하게 real, fake sample을 만들고 각각에 대해 -1, +1 을 label로 설정해줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldg9G3omK63_"
      },
      "source": [
        "# load images\r\n",
        "def load_real_samples():\r\n",
        "\t# load dataset\r\n",
        "\t(trainX, trainy), (_, _) = load_data()\r\n",
        "\t# select all of the examples for a given class\r\n",
        "\tselected_ix = trainy == 7\r\n",
        "\tX = trainX[selected_ix]\r\n",
        "\t# expand to 3d, e.g. add channels\r\n",
        "\tX = expand_dims(X, axis=-1)\r\n",
        "\t# convert from ints to floats\r\n",
        "\tX = X.astype('float32')\r\n",
        "\t# scale from [0,255] to [-1,1]\r\n",
        "\tX = (X - 127.5) / 127.5\r\n",
        "\treturn X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfCZZundK-66"
      },
      "source": [
        "# select real samples\r\n",
        "def generate_real_samples(dataset, n_samples):\r\n",
        "\t# choose random instances\r\n",
        "\tix = randint(0, dataset.shape[0], n_samples)\r\n",
        "\t# select images\r\n",
        "\tX = dataset[ix]\r\n",
        "\t# generate class labels, -1 for 'real'\r\n",
        "\ty = -ones((n_samples, 1))\r\n",
        "\treturn X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnSGNC5BLB0G"
      },
      "source": [
        "# generate points in latent space as input for the generator\r\n",
        "def generate_latent_points(latent_dim, n_samples):\r\n",
        "\t# generate points in the latent space\r\n",
        "\tx_input = randn(latent_dim * n_samples)\r\n",
        "\t# reshape into a batch of inputs for the network\r\n",
        "\tx_input = x_input.reshape(n_samples, latent_dim)\r\n",
        "\treturn x_input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g79iaHTqLDs2"
      },
      "source": [
        "# use the generator to generate n fake examples, with class labels\r\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\r\n",
        "\t# generate points in latent space\r\n",
        "\tx_input = generate_latent_points(latent_dim, n_samples)\r\n",
        "\t# predict outputs\r\n",
        "\tX = generator.predict(x_input)\r\n",
        "\t# create class labels with 1.0 for 'fake'\r\n",
        "\ty = ones((n_samples, 1))\r\n",
        "\treturn X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sgv6Hf3ALFbG"
      },
      "source": [
        "# generate samples and save as a plot and save the model\r\n",
        "def summarize_performance(step, g_model, latent_dim, n_samples=100):\r\n",
        "\t# prepare fake examples\r\n",
        "\tX, _ = generate_fake_samples(g_model, latent_dim, n_samples)\r\n",
        "\t# scale from [-1,1] to [0,1]\r\n",
        "\tX = (X + 1) / 2.0\r\n",
        "\t# plot images\r\n",
        "\tfor i in range(10 * 10):\r\n",
        "\t\t# define subplot\r\n",
        "\t\tpyplot.subplot(10, 10, 1 + i)\r\n",
        "\t\t# turn off axis\r\n",
        "\t\tpyplot.axis('off')\r\n",
        "\t\t# plot raw pixel data\r\n",
        "\t\tpyplot.imshow(X[i, :, :, 0], cmap='gray_r')\r\n",
        "\t# save plot to file\r\n",
        "\tfilename1 = 'generated_plot_%04d.png' % (step+1)\r\n",
        "\tpyplot.savefig(filename1)\r\n",
        "\tpyplot.close()\r\n",
        "\t# save the generator model\r\n",
        "\tfilename2 = 'model_%04d.h5' % (step+1)\r\n",
        "\tg_model.save(filename2)\r\n",
        "\tprint('>Saved: %s and %s' % (filename1, filename2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bO6_irNLJ2O"
      },
      "source": [
        "# create a line plot of loss for the gan and save to file\r\n",
        "def plot_history(d1_hist, d2_hist, g_hist):\r\n",
        "\t# plot history\r\n",
        "\tpyplot.plot(d1_hist, label='crit_real')\r\n",
        "\tpyplot.plot(d2_hist, label='crit_fake')\r\n",
        "\tpyplot.plot(g_hist, label='gen')\r\n",
        "\tpyplot.legend()\r\n",
        "\tpyplot.savefig('plot_line_plot_loss.png')\r\n",
        "\tpyplot.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Qlg7_NFLLyC"
      },
      "source": [
        "# train the generator and critic\r\n",
        "def train(g_model, c_model, gan_model, dataset, latent_dim, n_epochs=10, n_batch=64, n_critic=5):\r\n",
        "\t# calculate the number of batches per training epoch\r\n",
        "\tbat_per_epo = int(dataset.shape[0] / n_batch)\r\n",
        "\t# calculate the number of training iterations\r\n",
        "\tn_steps = bat_per_epo * n_epochs\r\n",
        "\t# calculate the size of half a batch of samples\r\n",
        "\thalf_batch = int(n_batch / 2)\r\n",
        "\t# lists for keeping track of loss\r\n",
        "\tc1_hist, c2_hist, g_hist = list(), list(), list()\r\n",
        "\t# manually enumerate epochs\r\n",
        "\tfor i in range(n_steps):\r\n",
        "\t\t# update the critic more than the generator\r\n",
        "\t\tc1_tmp, c2_tmp = list(), list()\r\n",
        "\t\tfor _ in range(n_critic):\r\n",
        "\t\t\t# get randomly selected 'real' samples\r\n",
        "\t\t\tX_real, y_real = generate_real_samples(dataset, half_batch)\r\n",
        "\t\t\t# update critic model weights\r\n",
        "\t\t\tc_loss1 = c_model.train_on_batch(X_real, y_real)\r\n",
        "\t\t\tc1_tmp.append(c_loss1)\r\n",
        "\t\t\t# generate 'fake' examples\r\n",
        "\t\t\tX_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\r\n",
        "\t\t\t# update critic model weights\r\n",
        "\t\t\tc_loss2 = c_model.train_on_batch(X_fake, y_fake)\r\n",
        "\t\t\tc2_tmp.append(c_loss2)\r\n",
        "\t\t# store critic loss\r\n",
        "\t\tc1_hist.append(mean(c1_tmp))\r\n",
        "\t\tc2_hist.append(mean(c2_tmp))\r\n",
        "\t\t# prepare points in latent space as input for the generator\r\n",
        "\t\tX_gan = generate_latent_points(latent_dim, n_batch)\r\n",
        "\t\t# create inverted labels for the fake samples\r\n",
        "\t\ty_gan = -ones((n_batch, 1))\r\n",
        "\t\t# update the generator via the critic's error\r\n",
        "\t\tg_loss = gan_model.train_on_batch(X_gan, y_gan)\r\n",
        "\t\tg_hist.append(g_loss)\r\n",
        "\t\t# summarize loss on this batch\r\n",
        "\t\tprint('>%d, c1=%.3f, c2=%.3f g=%.3f' % (i+1, c1_hist[-1], c2_hist[-1], g_loss))\r\n",
        "\t\t# evaluate the model performance every 'epoch'\r\n",
        "\t\tif (i+1) % bat_per_epo == 0:\r\n",
        "\t\t\tsummarize_performance(i, g_model, latent_dim)\r\n",
        "\t# line plots of loss\r\n",
        "\tplot_history(c1_hist, c2_hist, g_hist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7nYlxtCLOUe"
      },
      "source": [
        "# size of the latent space\r\n",
        "latent_dim = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF2MpTYhLSNB"
      },
      "source": [
        "# create the critic\r\n",
        "critic = define_critic()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rdJwlueLSa3"
      },
      "source": [
        "# create the generator\r\n",
        "generator = define_generator(latent_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HI0S7pMCLSjv"
      },
      "source": [
        "# create the gan\r\n",
        "gan_model = define_gan(generator, critic)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcamgS5BLSpJ",
        "outputId": "e340fe7f-1ae2-4d69-c2b1-7541aea8d6e2"
      },
      "source": [
        "# load image data\r\n",
        "dataset = load_real_samples()\r\n",
        "print(dataset.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "(6265, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zXs0jjELXCR",
        "outputId": "c52cdcfd-f7f4-45b5-ced6-a27973cbe320"
      },
      "source": [
        "# train model\r\n",
        "train(generator, critic, gan_model, dataset, latent_dim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">1, c1=-2.093, c2=0.039 g=-0.451\n",
            ">2, c1=-6.552, c2=0.126 g=-1.705\n",
            ">3, c1=-9.801, c2=0.195 g=-2.771\n",
            ">4, c1=-12.063, c2=0.262 g=-3.654\n",
            ">5, c1=-14.278, c2=0.325 g=-4.973\n",
            ">6, c1=-16.481, c2=0.387 g=-5.933\n",
            ">7, c1=-18.076, c2=0.483 g=-6.891\n",
            ">8, c1=-18.622, c2=0.538 g=-7.695\n",
            ">9, c1=-20.449, c2=0.624 g=-8.787\n",
            ">10, c1=-21.319, c2=0.695 g=-10.021\n",
            ">11, c1=-21.959, c2=0.795 g=-10.813\n",
            ">12, c1=-24.063, c2=0.876 g=-11.631\n",
            ">13, c1=-24.211, c2=0.960 g=-12.271\n",
            ">14, c1=-25.077, c2=1.055 g=-13.310\n",
            ">15, c1=-25.981, c2=1.128 g=-14.318\n",
            ">16, c1=-27.447, c2=1.212 g=-14.925\n",
            ">17, c1=-27.227, c2=1.265 g=-15.344\n",
            ">18, c1=-28.518, c2=1.335 g=-16.321\n",
            ">19, c1=-28.274, c2=1.398 g=-16.753\n",
            ">20, c1=-29.125, c2=1.451 g=-16.674\n",
            ">21, c1=-29.791, c2=1.470 g=-18.304\n",
            ">22, c1=-30.993, c2=1.457 g=-17.895\n",
            ">23, c1=-31.110, c2=1.466 g=-18.449\n",
            ">24, c1=-31.919, c2=1.445 g=-19.369\n",
            ">25, c1=-31.630, c2=1.370 g=-20.192\n",
            ">26, c1=-32.683, c2=1.414 g=-20.781\n",
            ">27, c1=-32.873, c2=1.227 g=-21.320\n",
            ">28, c1=-34.091, c2=1.160 g=-22.332\n",
            ">29, c1=-33.811, c2=0.896 g=-23.333\n",
            ">30, c1=-34.414, c2=0.684 g=-22.963\n",
            ">31, c1=-34.929, c2=0.337 g=-24.105\n",
            ">32, c1=-35.028, c2=-0.054 g=-26.048\n",
            ">33, c1=-35.643, c2=-0.546 g=-25.225\n",
            ">34, c1=-37.586, c2=-1.432 g=-25.798\n",
            ">35, c1=-36.994, c2=-1.838 g=-27.002\n",
            ">36, c1=-37.044, c2=-2.871 g=-27.766\n",
            ">37, c1=-37.889, c2=-3.805 g=-27.934\n",
            ">38, c1=-37.787, c2=-4.838 g=-28.706\n",
            ">39, c1=-38.948, c2=-6.064 g=-29.909\n",
            ">40, c1=-39.302, c2=-7.328 g=-30.496\n",
            ">41, c1=-39.306, c2=-8.939 g=-30.011\n",
            ">42, c1=-40.416, c2=-10.181 g=-31.439\n",
            ">43, c1=-41.509, c2=-11.794 g=-33.132\n",
            ">44, c1=-40.452, c2=-13.473 g=-33.716\n",
            ">45, c1=-41.253, c2=-14.942 g=-34.509\n",
            ">46, c1=-41.655, c2=-16.406 g=-35.030\n",
            ">47, c1=-42.317, c2=-17.889 g=-35.817\n",
            ">48, c1=-42.300, c2=-19.735 g=-36.606\n",
            ">49, c1=-44.366, c2=-21.086 g=-37.206\n",
            ">50, c1=-44.310, c2=-22.595 g=-38.375\n",
            ">51, c1=-44.371, c2=-24.025 g=-38.383\n",
            ">52, c1=-44.924, c2=-25.515 g=-39.762\n",
            ">53, c1=-46.131, c2=-26.833 g=-40.291\n",
            ">54, c1=-47.050, c2=-28.090 g=-42.499\n",
            ">55, c1=-46.775, c2=-29.610 g=-42.674\n",
            ">56, c1=-48.307, c2=-30.669 g=-43.097\n",
            ">57, c1=-48.866, c2=-31.866 g=-44.574\n",
            ">58, c1=-49.226, c2=-32.878 g=-45.229\n",
            ">59, c1=-50.715, c2=-33.879 g=-45.818\n",
            ">60, c1=-50.451, c2=-35.047 g=-46.688\n",
            ">61, c1=-50.927, c2=-36.249 g=-47.566\n",
            ">62, c1=-52.077, c2=-36.988 g=-48.353\n",
            ">63, c1=-51.793, c2=-38.373 g=-50.421\n",
            ">64, c1=-53.177, c2=-39.036 g=-50.376\n",
            ">65, c1=-53.627, c2=-40.194 g=-50.977\n",
            ">66, c1=-54.047, c2=-40.727 g=-51.976\n",
            ">67, c1=-55.081, c2=-41.951 g=-52.238\n",
            ">68, c1=-55.378, c2=-42.431 g=-53.637\n",
            ">69, c1=-55.714, c2=-43.735 g=-54.607\n",
            ">70, c1=-57.333, c2=-44.321 g=-54.958\n",
            ">71, c1=-57.934, c2=-45.536 g=-55.673\n",
            ">72, c1=-58.997, c2=-46.008 g=-56.816\n",
            ">73, c1=-58.784, c2=-46.971 g=-57.559\n",
            ">74, c1=-59.545, c2=-47.712 g=-58.106\n",
            ">75, c1=-60.462, c2=-48.701 g=-59.817\n",
            ">76, c1=-60.610, c2=-49.297 g=-59.636\n",
            ">77, c1=-61.927, c2=-50.305 g=-60.771\n",
            ">78, c1=-62.211, c2=-50.903 g=-61.285\n",
            ">79, c1=-63.748, c2=-51.969 g=-62.814\n",
            ">80, c1=-63.747, c2=-52.508 g=-63.424\n",
            ">81, c1=-65.275, c2=-53.440 g=-63.217\n",
            ">82, c1=-65.615, c2=-54.088 g=-65.107\n",
            ">83, c1=-66.063, c2=-55.194 g=-66.141\n",
            ">84, c1=-66.578, c2=-55.643 g=-66.758\n",
            ">85, c1=-66.810, c2=-56.627 g=-66.793\n",
            ">86, c1=-68.338, c2=-57.284 g=-68.448\n",
            ">87, c1=-68.362, c2=-58.009 g=-69.288\n",
            ">88, c1=-69.334, c2=-58.963 g=-69.344\n",
            ">89, c1=-69.678, c2=-59.704 g=-70.451\n",
            ">90, c1=-71.686, c2=-60.390 g=-71.449\n",
            ">91, c1=-71.306, c2=-61.199 g=-71.667\n",
            ">92, c1=-71.952, c2=-62.063 g=-73.029\n",
            ">93, c1=-72.627, c2=-62.590 g=-73.442\n",
            ">94, c1=-73.476, c2=-63.590 g=-74.699\n",
            ">95, c1=-73.672, c2=-64.145 g=-75.046\n",
            ">96, c1=-74.159, c2=-65.183 g=-75.710\n",
            ">97, c1=-75.171, c2=-65.464 g=-76.143\n",
            ">Saved: generated_plot_0097.png and model_0097.h5\n",
            ">98, c1=-76.672, c2=-66.753 g=-77.710\n",
            ">99, c1=-76.578, c2=-67.022 g=-78.470\n",
            ">100, c1=-78.330, c2=-68.196 g=-79.538\n",
            ">101, c1=-78.834, c2=-68.733 g=-80.094\n",
            ">102, c1=-78.411, c2=-69.741 g=-80.671\n",
            ">103, c1=-80.146, c2=-70.449 g=-81.887\n",
            ">104, c1=-80.170, c2=-71.089 g=-82.823\n",
            ">105, c1=-81.728, c2=-71.980 g=-83.094\n",
            ">106, c1=-82.385, c2=-72.760 g=-84.378\n",
            ">107, c1=-82.476, c2=-73.397 g=-84.489\n",
            ">108, c1=-83.160, c2=-74.176 g=-85.538\n",
            ">109, c1=-83.708, c2=-74.939 g=-86.650\n",
            ">110, c1=-85.304, c2=-75.680 g=-87.904\n",
            ">111, c1=-85.771, c2=-76.379 g=-87.884\n",
            ">112, c1=-86.760, c2=-77.401 g=-89.085\n",
            ">113, c1=-86.933, c2=-77.962 g=-89.833\n",
            ">114, c1=-88.238, c2=-78.967 g=-90.361\n",
            ">115, c1=-88.261, c2=-79.498 g=-91.336\n",
            ">116, c1=-89.698, c2=-80.552 g=-92.052\n",
            ">117, c1=-89.927, c2=-80.619 g=-93.482\n",
            ">118, c1=-90.680, c2=-81.832 g=-94.514\n",
            ">119, c1=-91.367, c2=-82.636 g=-95.134\n",
            ">120, c1=-92.477, c2=-83.303 g=-96.202\n",
            ">121, c1=-91.846, c2=-84.074 g=-95.912\n",
            ">122, c1=-93.210, c2=-85.092 g=-96.886\n",
            ">123, c1=-93.515, c2=-85.485 g=-98.302\n",
            ">124, c1=-95.171, c2=-86.542 g=-98.945\n",
            ">125, c1=-95.890, c2=-87.315 g=-99.893\n",
            ">126, c1=-96.194, c2=-87.929 g=-100.707\n",
            ">127, c1=-97.227, c2=-88.982 g=-101.697\n",
            ">128, c1=-97.738, c2=-89.485 g=-102.031\n",
            ">129, c1=-98.715, c2=-90.658 g=-103.353\n",
            ">130, c1=-99.536, c2=-91.106 g=-104.115\n",
            ">131, c1=-100.562, c2=-92.074 g=-105.036\n",
            ">132, c1=-100.928, c2=-92.672 g=-105.428\n",
            ">133, c1=-101.326, c2=-93.593 g=-106.113\n",
            ">134, c1=-102.379, c2=-94.359 g=-107.639\n",
            ">135, c1=-103.486, c2=-94.885 g=-108.617\n",
            ">136, c1=-103.375, c2=-95.726 g=-109.057\n",
            ">137, c1=-104.879, c2=-96.783 g=-110.383\n",
            ">138, c1=-104.558, c2=-97.253 g=-110.568\n",
            ">139, c1=-106.222, c2=-98.390 g=-111.622\n",
            ">140, c1=-107.870, c2=-98.774 g=-112.936\n",
            ">141, c1=-108.119, c2=-99.827 g=-113.528\n",
            ">142, c1=-108.428, c2=-100.605 g=-114.460\n",
            ">143, c1=-109.652, c2=-101.257 g=-114.947\n",
            ">144, c1=-110.216, c2=-102.274 g=-116.224\n",
            ">145, c1=-110.649, c2=-102.864 g=-116.397\n",
            ">146, c1=-111.043, c2=-103.851 g=-117.808\n",
            ">147, c1=-112.698, c2=-104.529 g=-118.725\n",
            ">148, c1=-113.121, c2=-105.440 g=-119.779\n",
            ">149, c1=-113.726, c2=-106.092 g=-120.385\n",
            ">150, c1=-115.256, c2=-106.936 g=-121.043\n",
            ">151, c1=-115.743, c2=-107.533 g=-121.329\n",
            ">152, c1=-116.547, c2=-108.830 g=-122.529\n",
            ">153, c1=-116.347, c2=-109.346 g=-123.847\n",
            ">154, c1=-118.541, c2=-110.193 g=-124.704\n",
            ">155, c1=-118.033, c2=-110.832 g=-125.411\n",
            ">156, c1=-119.460, c2=-111.639 g=-125.966\n",
            ">157, c1=-120.420, c2=-112.772 g=-126.949\n",
            ">158, c1=-120.956, c2=-113.355 g=-128.183\n",
            ">159, c1=-121.472, c2=-114.195 g=-128.818\n",
            ">160, c1=-122.142, c2=-114.996 g=-129.952\n",
            ">161, c1=-122.564, c2=-115.528 g=-130.873\n",
            ">162, c1=-124.105, c2=-116.508 g=-130.843\n",
            ">163, c1=-124.753, c2=-117.631 g=-132.234\n",
            ">164, c1=-126.212, c2=-118.056 g=-133.444\n",
            ">165, c1=-126.428, c2=-118.716 g=-133.911\n",
            ">166, c1=-127.701, c2=-119.573 g=-134.610\n",
            ">167, c1=-128.582, c2=-120.817 g=-135.623\n",
            ">168, c1=-129.320, c2=-121.555 g=-136.920\n",
            ">169, c1=-129.715, c2=-121.922 g=-137.338\n",
            ">170, c1=-130.111, c2=-123.294 g=-138.253\n",
            ">171, c1=-131.194, c2=-123.902 g=-139.363\n",
            ">172, c1=-131.695, c2=-124.786 g=-139.781\n",
            ">173, c1=-133.059, c2=-125.676 g=-140.583\n",
            ">174, c1=-133.746, c2=-126.575 g=-141.833\n",
            ">175, c1=-134.368, c2=-126.880 g=-143.046\n",
            ">176, c1=-135.324, c2=-127.689 g=-143.711\n",
            ">177, c1=-136.399, c2=-128.845 g=-144.086\n",
            ">178, c1=-137.088, c2=-129.990 g=-144.934\n",
            ">179, c1=-137.178, c2=-130.456 g=-146.243\n",
            ">180, c1=-138.680, c2=-131.297 g=-146.922\n",
            ">181, c1=-139.212, c2=-132.181 g=-147.810\n",
            ">182, c1=-140.960, c2=-132.769 g=-148.741\n",
            ">183, c1=-141.625, c2=-133.700 g=-149.257\n",
            ">184, c1=-141.644, c2=-134.950 g=-150.385\n",
            ">185, c1=-142.176, c2=-134.990 g=-150.989\n",
            ">186, c1=-143.182, c2=-136.442 g=-152.177\n",
            ">187, c1=-144.376, c2=-137.022 g=-152.894\n",
            ">188, c1=-145.422, c2=-138.059 g=-154.110\n",
            ">189, c1=-145.433, c2=-138.643 g=-154.742\n",
            ">190, c1=-147.406, c2=-139.623 g=-155.846\n",
            ">191, c1=-148.056, c2=-140.032 g=-156.446\n",
            ">192, c1=-147.817, c2=-141.394 g=-157.493\n",
            ">193, c1=-149.611, c2=-142.248 g=-158.148\n",
            ">194, c1=-150.050, c2=-143.180 g=-158.727\n",
            ">Saved: generated_plot_0194.png and model_0194.h5\n",
            ">195, c1=-151.131, c2=-144.129 g=-160.010\n",
            ">196, c1=-151.589, c2=-144.589 g=-161.006\n",
            ">197, c1=-153.264, c2=-145.525 g=-161.858\n",
            ">198, c1=-152.926, c2=-146.496 g=-162.477\n",
            ">199, c1=-153.952, c2=-147.449 g=-163.432\n",
            ">200, c1=-155.357, c2=-148.096 g=-164.445\n",
            ">201, c1=-155.438, c2=-148.877 g=-165.053\n",
            ">202, c1=-157.279, c2=-149.883 g=-166.070\n",
            ">203, c1=-157.745, c2=-150.725 g=-166.946\n",
            ">204, c1=-159.042, c2=-151.652 g=-167.793\n",
            ">205, c1=-159.754, c2=-152.522 g=-168.719\n",
            ">206, c1=-160.842, c2=-152.549 g=-168.256\n",
            ">207, c1=-162.391, c2=-154.362 g=-170.692\n",
            ">208, c1=-163.101, c2=-154.975 g=-171.795\n",
            ">209, c1=-163.129, c2=-155.755 g=-172.500\n",
            ">210, c1=-163.557, c2=-156.715 g=-172.913\n",
            ">211, c1=-165.379, c2=-157.770 g=-174.307\n",
            ">212, c1=-165.858, c2=-158.128 g=-174.663\n",
            ">213, c1=-166.604, c2=-159.318 g=-176.094\n",
            ">214, c1=-167.491, c2=-159.940 g=-176.725\n",
            ">215, c1=-168.588, c2=-160.977 g=-177.928\n",
            ">216, c1=-170.035, c2=-161.558 g=-178.749\n",
            ">217, c1=-170.318, c2=-162.669 g=-179.761\n",
            ">218, c1=-171.195, c2=-163.319 g=-180.426\n",
            ">219, c1=-171.866, c2=-164.499 g=-181.622\n",
            ">220, c1=-172.688, c2=-165.145 g=-182.520\n",
            ">221, c1=-173.860, c2=-165.832 g=-183.346\n",
            ">222, c1=-173.434, c2=-166.864 g=-183.942\n",
            ">223, c1=-175.667, c2=-167.917 g=-184.891\n",
            ">224, c1=-175.161, c2=-168.719 g=-185.758\n",
            ">225, c1=-177.240, c2=-168.696 g=-186.498\n",
            ">226, c1=-178.269, c2=-170.685 g=-187.927\n",
            ">227, c1=-178.346, c2=-171.190 g=-188.617\n",
            ">228, c1=-179.844, c2=-172.227 g=-189.747\n",
            ">229, c1=-180.088, c2=-172.943 g=-190.130\n",
            ">230, c1=-180.685, c2=-174.169 g=-191.404\n",
            ">231, c1=-181.099, c2=-174.765 g=-192.242\n",
            ">232, c1=-183.471, c2=-175.624 g=-193.245\n",
            ">233, c1=-184.471, c2=-176.535 g=-194.136\n",
            ">234, c1=-184.518, c2=-177.595 g=-194.226\n",
            ">235, c1=-185.650, c2=-178.796 g=-195.341\n",
            ">236, c1=-187.160, c2=-179.043 g=-197.103\n",
            ">237, c1=-187.918, c2=-179.885 g=-197.690\n",
            ">238, c1=-187.656, c2=-181.285 g=-198.452\n",
            ">239, c1=-187.840, c2=-182.087 g=-199.281\n",
            ">240, c1=-190.771, c2=-183.122 g=-200.420\n",
            ">241, c1=-190.950, c2=-183.713 g=-201.456\n",
            ">242, c1=-192.873, c2=-184.793 g=-202.726\n",
            ">243, c1=-193.770, c2=-185.160 g=-202.843\n",
            ">244, c1=-194.421, c2=-186.663 g=-204.174\n",
            ">245, c1=-194.806, c2=-186.373 g=-205.215\n",
            ">246, c1=-196.582, c2=-187.977 g=-205.781\n",
            ">247, c1=-197.157, c2=-189.391 g=-206.978\n",
            ">248, c1=-198.957, c2=-190.282 g=-208.331\n",
            ">249, c1=-199.451, c2=-190.508 g=-209.190\n",
            ">250, c1=-200.624, c2=-191.701 g=-210.158\n",
            ">251, c1=-200.012, c2=-191.876 g=-210.581\n",
            ">252, c1=-201.297, c2=-193.787 g=-211.925\n",
            ">253, c1=-202.094, c2=-194.049 g=-213.078\n",
            ">254, c1=-203.584, c2=-195.146 g=-213.835\n",
            ">255, c1=-203.596, c2=-195.951 g=-214.934\n",
            ">256, c1=-205.955, c2=-196.753 g=-215.192\n",
            ">257, c1=-205.961, c2=-198.666 g=-216.116\n",
            ">258, c1=-207.758, c2=-199.613 g=-217.527\n",
            ">259, c1=-208.469, c2=-199.397 g=-218.005\n",
            ">260, c1=-208.782, c2=-201.159 g=-219.569\n",
            ">261, c1=-208.812, c2=-201.214 g=-219.561\n",
            ">262, c1=-209.042, c2=-202.913 g=-221.113\n",
            ">263, c1=-211.165, c2=-203.754 g=-222.317\n",
            ">264, c1=-213.283, c2=-204.248 g=-223.368\n",
            ">265, c1=-213.495, c2=-204.832 g=-224.323\n",
            ">266, c1=-215.182, c2=-206.190 g=-225.422\n",
            ">267, c1=-215.203, c2=-206.339 g=-225.011\n",
            ">268, c1=-216.881, c2=-208.504 g=-226.916\n",
            ">269, c1=-217.208, c2=-209.169 g=-228.011\n",
            ">270, c1=-217.854, c2=-210.190 g=-229.115\n",
            ">271, c1=-218.880, c2=-210.758 g=-229.704\n",
            ">272, c1=-219.822, c2=-212.111 g=-230.724\n",
            ">273, c1=-221.909, c2=-212.891 g=-232.095\n",
            ">274, c1=-222.338, c2=-213.333 g=-232.721\n",
            ">275, c1=-222.081, c2=-214.843 g=-234.085\n",
            ">276, c1=-223.133, c2=-214.818 g=-233.481\n",
            ">277, c1=-224.387, c2=-216.987 g=-235.531\n",
            ">278, c1=-225.249, c2=-216.633 g=-236.248\n",
            ">279, c1=-227.588, c2=-218.838 g=-237.655\n",
            ">280, c1=-227.267, c2=-218.032 g=-237.923\n",
            ">281, c1=-228.814, c2=-220.569 g=-239.786\n",
            ">282, c1=-228.666, c2=-220.095 g=-240.418\n",
            ">283, c1=-229.570, c2=-221.580 g=-241.231\n",
            ">284, c1=-231.475, c2=-223.227 g=-242.690\n",
            ">285, c1=-232.811, c2=-223.547 g=-242.712\n",
            ">286, c1=-233.142, c2=-225.246 g=-244.354\n",
            ">287, c1=-234.262, c2=-224.714 g=-245.622\n",
            ">288, c1=-233.272, c2=-225.838 g=-245.882\n",
            ">289, c1=-235.782, c2=-227.923 g=-247.313\n",
            ">290, c1=-236.650, c2=-227.287 g=-248.439\n",
            ">291, c1=-239.140, c2=-228.674 g=-249.582\n",
            ">Saved: generated_plot_0291.png and model_0291.h5\n",
            ">292, c1=-237.994, c2=-229.902 g=-250.483\n",
            ">293, c1=-239.614, c2=-231.164 g=-251.324\n",
            ">294, c1=-241.217, c2=-232.403 g=-252.315\n",
            ">295, c1=-242.637, c2=-233.446 g=-253.837\n",
            ">296, c1=-241.929, c2=-233.779 g=-254.550\n",
            ">297, c1=-242.627, c2=-232.900 g=-253.620\n",
            ">298, c1=-245.025, c2=-236.814 g=-256.383\n",
            ">299, c1=-245.685, c2=-236.157 g=-257.326\n",
            ">300, c1=-246.806, c2=-237.565 g=-257.799\n",
            ">301, c1=-247.908, c2=-239.250 g=-259.406\n",
            ">302, c1=-249.894, c2=-238.307 g=-260.140\n",
            ">303, c1=-249.645, c2=-240.633 g=-261.187\n",
            ">304, c1=-250.355, c2=-241.632 g=-262.088\n",
            ">305, c1=-250.502, c2=-242.443 g=-262.878\n",
            ">306, c1=-252.671, c2=-243.795 g=-264.208\n",
            ">307, c1=-253.683, c2=-243.291 g=-264.208\n",
            ">308, c1=-255.320, c2=-245.864 g=-266.187\n",
            ">309, c1=-256.302, c2=-245.577 g=-267.211\n",
            ">310, c1=-256.568, c2=-244.817 g=-266.897\n",
            ">311, c1=-256.404, c2=-248.669 g=-268.419\n",
            ">312, c1=-258.399, c2=-249.789 g=-270.343\n",
            ">313, c1=-259.724, c2=-249.563 g=-271.283\n",
            ">314, c1=-259.585, c2=-247.913 g=-271.605\n",
            ">315, c1=-259.831, c2=-251.068 g=-272.749\n",
            ">316, c1=-261.870, c2=-252.469 g=-273.618\n",
            ">317, c1=-261.983, c2=-248.072 g=-273.107\n",
            ">318, c1=-262.641, c2=-254.398 g=-274.742\n",
            ">319, c1=-263.232, c2=-255.749 g=-276.473\n",
            ">320, c1=-265.242, c2=-256.238 g=-277.799\n",
            ">321, c1=-266.142, c2=-256.714 g=-278.264\n",
            ">322, c1=-267.401, c2=-258.846 g=-279.603\n",
            ">323, c1=-268.800, c2=-259.317 g=-279.848\n",
            ">324, c1=-270.288, c2=-261.534 g=-281.638\n",
            ">325, c1=-268.652, c2=-257.489 g=-280.071\n",
            ">326, c1=-272.352, c2=-263.707 g=-283.485\n",
            ">327, c1=-270.711, c2=-260.253 g=-283.874\n",
            ">328, c1=-272.904, c2=-263.105 g=-283.195\n",
            ">329, c1=-273.805, c2=-266.515 g=-285.153\n",
            ">330, c1=-273.747, c2=-267.732 g=-287.289\n",
            ">331, c1=-277.485, c2=-268.456 g=-289.330\n",
            ">332, c1=-278.128, c2=-266.339 g=-288.665\n",
            ">333, c1=-279.268, c2=-269.974 g=-291.188\n",
            ">334, c1=-279.868, c2=-267.430 g=-289.908\n",
            ">335, c1=-278.620, c2=-271.741 g=-292.687\n",
            ">336, c1=-281.831, c2=-271.259 g=-292.848\n",
            ">337, c1=-281.281, c2=-273.295 g=-294.732\n",
            ">338, c1=-283.168, c2=-270.436 g=-294.428\n",
            ">339, c1=-285.140, c2=-274.953 g=-296.625\n",
            ">340, c1=-282.963, c2=-270.100 g=-293.810\n",
            ">341, c1=-285.566, c2=-277.156 g=-297.652\n",
            ">342, c1=-286.958, c2=-277.619 g=-298.462\n",
            ">343, c1=-288.099, c2=-278.916 g=-299.845\n",
            ">344, c1=-289.191, c2=-280.280 g=-301.519\n",
            ">345, c1=-291.161, c2=-278.576 g=-302.447\n",
            ">346, c1=-291.436, c2=-275.523 g=-300.999\n",
            ">347, c1=-291.232, c2=-281.812 g=-303.155\n",
            ">348, c1=-291.237, c2=-282.206 g=-304.226\n",
            ">349, c1=-291.628, c2=-282.569 g=-305.292\n",
            ">350, c1=-295.208, c2=-283.390 g=-305.714\n",
            ">351, c1=-296.186, c2=-287.155 g=-308.589\n",
            ">352, c1=-295.672, c2=-277.732 g=-305.659\n",
            ">353, c1=-297.691, c2=-287.373 g=-309.176\n",
            ">354, c1=-297.573, c2=-286.366 g=-309.124\n",
            ">355, c1=-299.005, c2=-288.474 g=-310.714\n",
            ">356, c1=-297.817, c2=-286.668 g=-310.443\n",
            ">357, c1=-300.565, c2=-291.101 g=-313.656\n",
            ">358, c1=-300.010, c2=-286.342 g=-313.545\n",
            ">359, c1=-299.749, c2=-278.153 g=-309.611\n",
            ">360, c1=-301.560, c2=-294.114 g=-314.608\n",
            ">361, c1=-301.553, c2=-292.519 g=-315.972\n",
            ">362, c1=-305.236, c2=-293.877 g=-316.170\n",
            ">363, c1=-304.083, c2=-294.496 g=-317.906\n",
            ">364, c1=-306.180, c2=-294.590 g=-318.500\n",
            ">365, c1=-306.132, c2=-294.241 g=-320.128\n",
            ">366, c1=-308.170, c2=-292.306 g=-319.271\n",
            ">367, c1=-307.882, c2=-295.131 g=-319.693\n",
            ">368, c1=-309.686, c2=-297.072 g=-321.227\n",
            ">369, c1=-309.877, c2=-298.795 g=-322.572\n",
            ">370, c1=-311.251, c2=-297.296 g=-323.127\n",
            ">371, c1=-311.694, c2=-301.389 g=-324.656\n",
            ">372, c1=-311.042, c2=-294.334 g=-323.402\n",
            ">373, c1=-313.151, c2=-299.271 g=-326.219\n",
            ">374, c1=-309.613, c2=-273.190 g=-319.660\n",
            ">375, c1=-307.175, c2=-299.787 g=-325.459\n",
            ">376, c1=-304.987, c2=-289.385 g=-322.783\n",
            ">377, c1=-309.471, c2=-301.578 g=-325.022\n",
            ">378, c1=-313.399, c2=-304.404 g=-327.761\n",
            ">379, c1=-313.747, c2=-303.701 g=-330.253\n",
            ">380, c1=-313.060, c2=-296.314 g=-327.907\n",
            ">381, c1=-314.313, c2=-306.604 g=-331.442\n",
            ">382, c1=-317.615, c2=-297.994 g=-330.032\n",
            ">383, c1=-316.001, c2=-300.410 g=-330.913\n",
            ">384, c1=-313.416, c2=-297.885 g=-331.473\n",
            ">385, c1=-314.078, c2=-300.291 g=-331.331\n",
            ">386, c1=-313.962, c2=-301.210 g=-333.203\n",
            ">387, c1=-310.409, c2=-287.839 g=-331.769\n",
            ">388, c1=-309.355, c2=-302.577 g=-334.005\n",
            ">Saved: generated_plot_0388.png and model_0388.h5\n",
            ">389, c1=-309.547, c2=-298.131 g=-333.498\n",
            ">390, c1=-314.054, c2=-299.345 g=-335.244\n",
            ">391, c1=-314.882, c2=-290.455 g=-334.540\n",
            ">392, c1=-310.301, c2=-287.952 g=-331.216\n",
            ">393, c1=-308.620, c2=-302.920 g=-335.928\n",
            ">394, c1=-302.743, c2=-266.126 g=-330.026\n",
            ">395, c1=-291.735, c2=-297.182 g=-331.868\n",
            ">396, c1=-312.002, c2=-299.676 g=-336.382\n",
            ">397, c1=-306.978, c2=-277.285 g=-333.767\n",
            ">398, c1=-292.701, c2=-265.285 g=-331.115\n",
            ">399, c1=-279.325, c2=-251.016 g=-328.579\n",
            ">400, c1=-263.540, c2=-229.142 g=-324.631\n",
            ">401, c1=-245.619, c2=-199.120 g=-317.646\n",
            ">402, c1=-202.435, c2=-156.935 g=-315.536\n",
            ">403, c1=-222.658, c2=-208.454 g=-317.534\n",
            ">404, c1=-221.839, c2=-218.734 g=-318.000\n",
            ">405, c1=-190.009, c2=-138.421 g=-305.454\n",
            ">406, c1=-174.605, c2=-178.088 g=-307.310\n",
            ">407, c1=-162.148, c2=-175.779 g=-305.391\n",
            ">408, c1=-165.298, c2=-215.139 g=-313.237\n",
            ">409, c1=-182.872, c2=-177.718 g=-307.583\n",
            ">410, c1=-116.376, c2=-121.958 g=-292.273\n",
            ">411, c1=-113.835, c2=-107.166 g=-283.597\n",
            ">412, c1=-84.640, c2=-116.589 g=-279.523\n",
            ">413, c1=-71.506, c2=-67.912 g=-258.253\n",
            ">414, c1=-43.359, c2=-59.780 g=-237.531\n",
            ">415, c1=-4.882, c2=-39.580 g=-207.517\n",
            ">416, c1=-2.986, c2=-37.120 g=-188.559\n",
            ">417, c1=24.391, c2=-47.898 g=-173.162\n",
            ">418, c1=-8.459, c2=-56.667 g=-178.781\n",
            ">419, c1=8.744, c2=-59.936 g=-174.266\n",
            ">420, c1=-3.055, c2=-64.992 g=-170.993\n",
            ">421, c1=4.617, c2=-75.881 g=-170.998\n",
            ">422, c1=-14.909, c2=-85.918 g=-171.490\n",
            ">423, c1=-18.158, c2=-96.707 g=-173.584\n",
            ">424, c1=-18.953, c2=-105.583 g=-169.841\n",
            ">425, c1=-35.862, c2=-126.576 g=-175.151\n",
            ">426, c1=-44.737, c2=-139.161 g=-180.477\n",
            ">427, c1=-50.627, c2=-153.235 g=-188.471\n",
            ">428, c1=-61.707, c2=-168.064 g=-195.480\n",
            ">429, c1=-58.741, c2=-176.026 g=-195.745\n",
            ">430, c1=-86.581, c2=-176.514 g=-201.458\n",
            ">431, c1=-88.189, c2=-176.942 g=-202.771\n",
            ">432, c1=-93.502, c2=-188.669 g=-208.075\n",
            ">433, c1=-95.755, c2=-188.493 g=-212.940\n",
            ">434, c1=-118.670, c2=-192.821 g=-220.169\n",
            ">435, c1=-117.907, c2=-186.022 g=-224.980\n",
            ">436, c1=-123.784, c2=-187.095 g=-227.017\n",
            ">437, c1=-106.842, c2=-188.535 g=-229.853\n",
            ">438, c1=-116.996, c2=-177.249 g=-232.623\n",
            ">439, c1=-120.586, c2=-172.761 g=-236.372\n",
            ">440, c1=-113.919, c2=-166.713 g=-240.370\n",
            ">441, c1=-113.741, c2=-158.021 g=-239.787\n",
            ">442, c1=-115.247, c2=-140.399 g=-239.766\n",
            ">443, c1=-119.071, c2=-139.088 g=-242.225\n",
            ">444, c1=-123.498, c2=-136.616 g=-241.857\n",
            ">445, c1=-124.309, c2=-127.798 g=-240.765\n",
            ">446, c1=-130.508, c2=-119.862 g=-237.521\n",
            ">447, c1=-128.273, c2=-108.528 g=-234.190\n",
            ">448, c1=-129.196, c2=-97.988 g=-228.974\n",
            ">449, c1=-143.359, c2=-88.000 g=-224.919\n",
            ">450, c1=-138.214, c2=-79.090 g=-219.102\n",
            ">451, c1=-138.769, c2=-69.224 g=-214.936\n",
            ">452, c1=-161.177, c2=-65.822 g=-205.202\n",
            ">453, c1=-158.177, c2=-62.018 g=-199.067\n",
            ">454, c1=-176.161, c2=-71.055 g=-189.027\n",
            ">455, c1=-173.007, c2=-76.157 g=-175.607\n",
            ">456, c1=-187.827, c2=-86.275 g=-167.755\n",
            ">457, c1=-191.102, c2=-95.326 g=-157.897\n",
            ">458, c1=-198.770, c2=-105.384 g=-152.238\n",
            ">459, c1=-204.148, c2=-113.146 g=-137.036\n",
            ">460, c1=-206.882, c2=-125.571 g=-129.370\n",
            ">461, c1=-218.209, c2=-135.523 g=-119.009\n",
            ">462, c1=-225.086, c2=-141.939 g=-105.865\n",
            ">463, c1=-233.904, c2=-152.363 g=-96.032\n",
            ">464, c1=-233.473, c2=-152.772 g=-79.178\n",
            ">465, c1=-244.178, c2=-162.547 g=-61.740\n",
            ">466, c1=-249.146, c2=-165.898 g=-41.832\n",
            ">467, c1=-258.727, c2=-171.680 g=-16.417\n",
            ">468, c1=-263.689, c2=-179.705 g=6.454\n",
            ">469, c1=-269.116, c2=-189.435 g=30.517\n",
            ">470, c1=-275.428, c2=-195.592 g=52.605\n",
            ">471, c1=-282.630, c2=-207.626 g=67.828\n",
            ">472, c1=-292.562, c2=-211.700 g=86.246\n",
            ">473, c1=-296.883, c2=-225.526 g=111.376\n",
            ">474, c1=-304.838, c2=-235.921 g=139.835\n",
            ">475, c1=-312.909, c2=-248.436 g=161.613\n",
            ">476, c1=-318.188, c2=-260.765 g=182.090\n",
            ">477, c1=-324.717, c2=-270.185 g=203.973\n",
            ">478, c1=-333.204, c2=-280.669 g=222.270\n",
            ">479, c1=-337.634, c2=-289.419 g=238.890\n",
            ">480, c1=-346.832, c2=-297.502 g=247.382\n",
            ">481, c1=-348.911, c2=-304.950 g=258.018\n",
            ">482, c1=-355.754, c2=-311.250 g=269.235\n",
            ">483, c1=-359.559, c2=-318.091 g=275.700\n",
            ">484, c1=-363.573, c2=-321.148 g=283.599\n",
            ">485, c1=-367.732, c2=-326.500 g=286.144\n",
            ">Saved: generated_plot_0485.png and model_0485.h5\n",
            ">486, c1=-370.753, c2=-330.849 g=291.270\n",
            ">487, c1=-377.138, c2=-332.305 g=294.611\n",
            ">488, c1=-377.776, c2=-337.960 g=297.444\n",
            ">489, c1=-380.783, c2=-341.191 g=301.312\n",
            ">490, c1=-384.285, c2=-345.591 g=306.471\n",
            ">491, c1=-388.333, c2=-349.597 g=309.735\n",
            ">492, c1=-389.745, c2=-351.962 g=313.504\n",
            ">493, c1=-393.513, c2=-355.378 g=316.970\n",
            ">494, c1=-395.119, c2=-359.671 g=321.909\n",
            ">495, c1=-397.397, c2=-360.960 g=324.899\n",
            ">496, c1=-399.945, c2=-364.048 g=328.941\n",
            ">497, c1=-402.326, c2=-366.592 g=333.722\n",
            ">498, c1=-405.758, c2=-370.326 g=337.005\n",
            ">499, c1=-405.195, c2=-372.630 g=340.787\n",
            ">500, c1=-409.319, c2=-375.652 g=346.035\n",
            ">501, c1=-409.869, c2=-378.472 g=350.252\n",
            ">502, c1=-413.059, c2=-380.666 g=353.460\n",
            ">503, c1=-416.323, c2=-383.679 g=357.655\n",
            ">504, c1=-416.881, c2=-386.319 g=361.787\n",
            ">505, c1=-419.633, c2=-389.175 g=365.369\n",
            ">506, c1=-422.465, c2=-390.453 g=368.664\n",
            ">507, c1=-424.972, c2=-393.200 g=373.404\n",
            ">508, c1=-425.969, c2=-395.235 g=376.222\n",
            ">509, c1=-428.268, c2=-397.022 g=379.990\n",
            ">510, c1=-429.375, c2=-399.436 g=382.861\n",
            ">511, c1=-431.823, c2=-401.567 g=385.347\n",
            ">512, c1=-433.777, c2=-402.248 g=388.173\n",
            ">513, c1=-435.252, c2=-404.273 g=390.611\n",
            ">514, c1=-436.999, c2=-405.897 g=393.191\n",
            ">515, c1=-440.125, c2=-406.557 g=394.850\n",
            ">516, c1=-440.449, c2=-407.486 g=396.823\n",
            ">517, c1=-442.145, c2=-408.963 g=398.444\n",
            ">518, c1=-443.239, c2=-409.499 g=399.655\n",
            ">519, c1=-446.467, c2=-410.551 g=400.946\n",
            ">520, c1=-447.870, c2=-412.069 g=402.143\n",
            ">521, c1=-448.750, c2=-413.680 g=404.083\n",
            ">522, c1=-450.760, c2=-414.829 g=405.688\n",
            ">523, c1=-451.581, c2=-416.086 g=407.227\n",
            ">524, c1=-453.453, c2=-417.722 g=408.779\n",
            ">525, c1=-456.187, c2=-418.638 g=410.642\n",
            ">526, c1=-456.407, c2=-419.823 g=412.080\n",
            ">527, c1=-460.158, c2=-420.892 g=413.687\n",
            ">528, c1=-459.673, c2=-421.940 g=415.233\n",
            ">529, c1=-461.846, c2=-422.884 g=416.837\n",
            ">530, c1=-463.582, c2=-424.012 g=418.296\n",
            ">531, c1=-464.489, c2=-424.960 g=419.782\n",
            ">532, c1=-466.679, c2=-426.137 g=421.169\n",
            ">533, c1=-467.863, c2=-427.001 g=422.659\n",
            ">534, c1=-470.008, c2=-428.187 g=424.145\n",
            ">535, c1=-471.872, c2=-429.488 g=425.578\n",
            ">536, c1=-472.091, c2=-430.583 g=426.845\n",
            ">537, c1=-474.304, c2=-431.537 g=428.214\n",
            ">538, c1=-474.216, c2=-432.807 g=429.610\n",
            ">539, c1=-476.368, c2=-433.875 g=430.930\n",
            ">540, c1=-478.182, c2=-434.751 g=432.336\n",
            ">541, c1=-479.021, c2=-435.853 g=433.708\n",
            ">542, c1=-481.842, c2=-436.951 g=435.028\n",
            ">543, c1=-481.456, c2=-438.072 g=436.335\n",
            ">544, c1=-484.133, c2=-439.233 g=437.674\n",
            ">545, c1=-485.452, c2=-440.501 g=438.872\n",
            ">546, c1=-486.632, c2=-441.550 g=440.236\n",
            ">547, c1=-488.521, c2=-442.736 g=441.468\n",
            ">548, c1=-490.063, c2=-443.946 g=442.792\n",
            ">549, c1=-489.856, c2=-445.084 g=444.045\n",
            ">550, c1=-491.172, c2=-446.357 g=445.290\n",
            ">551, c1=-494.285, c2=-447.402 g=446.510\n",
            ">552, c1=-495.018, c2=-448.612 g=447.754\n",
            ">553, c1=-496.587, c2=-449.790 g=449.029\n",
            ">554, c1=-497.573, c2=-450.868 g=450.211\n",
            ">555, c1=-497.190, c2=-452.051 g=451.444\n",
            ">556, c1=-499.469, c2=-453.202 g=452.668\n",
            ">557, c1=-501.062, c2=-454.304 g=453.863\n",
            ">558, c1=-502.864, c2=-455.424 g=455.107\n",
            ">559, c1=-504.313, c2=-456.596 g=456.316\n",
            ">560, c1=-506.234, c2=-457.651 g=457.522\n",
            ">561, c1=-506.302, c2=-458.843 g=458.718\n",
            ">562, c1=-508.209, c2=-460.051 g=459.920\n",
            ">563, c1=-508.921, c2=-461.136 g=461.127\n",
            ">564, c1=-510.567, c2=-462.336 g=462.302\n",
            ">565, c1=-511.970, c2=-463.481 g=463.502\n",
            ">566, c1=-513.364, c2=-464.656 g=464.704\n",
            ">567, c1=-516.001, c2=-465.730 g=465.884\n",
            ">568, c1=-516.431, c2=-466.822 g=467.063\n",
            ">569, c1=-516.930, c2=-468.069 g=468.253\n",
            ">570, c1=-518.848, c2=-469.228 g=469.439\n",
            ">571, c1=-519.907, c2=-470.379 g=470.614\n",
            ">572, c1=-521.883, c2=-471.502 g=471.789\n",
            ">573, c1=-523.615, c2=-472.651 g=472.992\n",
            ">574, c1=-524.779, c2=-473.805 g=474.138\n",
            ">575, c1=-526.145, c2=-474.983 g=475.352\n",
            ">576, c1=-526.243, c2=-476.175 g=476.502\n",
            ">577, c1=-527.968, c2=-477.306 g=477.679\n",
            ">578, c1=-529.130, c2=-478.462 g=478.838\n",
            ">579, c1=-529.726, c2=-479.608 g=480.038\n",
            ">580, c1=-533.305, c2=-480.796 g=481.222\n",
            ">581, c1=-533.143, c2=-481.930 g=482.381\n",
            ">582, c1=-534.348, c2=-482.851 g=483.491\n",
            ">Saved: generated_plot_0582.png and model_0582.h5\n",
            ">583, c1=-536.711, c2=-483.986 g=484.680\n",
            ">584, c1=-536.386, c2=-485.245 g=485.824\n",
            ">585, c1=-538.210, c2=-486.260 g=486.930\n",
            ">586, c1=-539.916, c2=-487.544 g=487.906\n",
            ">587, c1=-540.484, c2=-488.639 g=489.186\n",
            ">588, c1=-541.757, c2=-489.641 g=490.350\n",
            ">589, c1=-542.806, c2=-491.312 g=491.500\n",
            ">590, c1=-545.380, c2=-492.190 g=492.663\n",
            ">591, c1=-545.576, c2=-493.344 g=493.838\n",
            ">592, c1=-546.846, c2=-494.607 g=494.947\n",
            ">593, c1=-547.386, c2=-495.962 g=496.165\n",
            ">594, c1=-549.924, c2=-496.790 g=497.290\n",
            ">595, c1=-551.146, c2=-498.081 g=498.460\n",
            ">596, c1=-553.037, c2=-499.200 g=499.622\n",
            ">597, c1=-553.539, c2=-499.920 g=500.779\n",
            ">598, c1=-555.566, c2=-500.929 g=501.861\n",
            ">599, c1=-557.099, c2=-501.818 g=502.865\n",
            ">600, c1=-557.790, c2=-503.115 g=504.239\n",
            ">601, c1=-558.093, c2=-504.885 g=505.345\n",
            ">602, c1=-559.900, c2=-506.141 g=506.425\n",
            ">603, c1=-561.250, c2=-507.043 g=507.635\n",
            ">604, c1=-562.448, c2=-508.492 g=508.771\n",
            ">605, c1=-564.433, c2=-509.181 g=509.996\n",
            ">606, c1=-565.964, c2=-510.370 g=511.223\n",
            ">607, c1=-566.270, c2=-511.247 g=512.216\n",
            ">608, c1=-568.227, c2=-512.554 g=513.512\n",
            ">609, c1=-569.258, c2=-513.635 g=514.653\n",
            ">610, c1=-570.374, c2=-515.296 g=515.844\n",
            ">611, c1=-569.857, c2=-516.538 g=517.161\n",
            ">612, c1=-573.133, c2=-517.952 g=518.276\n",
            ">613, c1=-573.998, c2=-519.393 g=519.455\n",
            ">614, c1=-573.787, c2=-520.401 g=520.699\n",
            ">615, c1=-575.918, c2=-521.584 g=521.824\n",
            ">616, c1=-576.917, c2=-522.773 g=523.190\n",
            ">617, c1=-579.669, c2=-524.104 g=524.332\n",
            ">618, c1=-581.244, c2=-525.113 g=525.579\n",
            ">619, c1=-582.966, c2=-526.395 g=526.735\n",
            ">620, c1=-583.477, c2=-527.564 g=527.958\n",
            ">621, c1=-585.503, c2=-528.776 g=529.236\n",
            ">622, c1=-586.009, c2=-529.987 g=530.444\n",
            ">623, c1=-586.151, c2=-531.193 g=531.532\n",
            ">624, c1=-587.866, c2=-532.317 g=532.840\n",
            ">625, c1=-589.898, c2=-533.529 g=534.075\n",
            ">626, c1=-591.149, c2=-534.844 g=535.214\n",
            ">627, c1=-593.454, c2=-535.927 g=536.481\n",
            ">628, c1=-594.729, c2=-537.227 g=537.746\n",
            ">629, c1=-595.588, c2=-538.397 g=538.866\n",
            ">630, c1=-597.257, c2=-539.513 g=540.162\n",
            ">631, c1=-598.732, c2=-540.642 g=541.275\n",
            ">632, c1=-600.374, c2=-541.955 g=542.499\n",
            ">633, c1=-601.003, c2=-543.051 g=543.668\n",
            ">634, c1=-602.342, c2=-544.334 g=544.947\n",
            ">635, c1=-603.658, c2=-545.533 g=546.119\n",
            ">636, c1=-605.643, c2=-546.643 g=547.333\n",
            ">637, c1=-605.439, c2=-547.824 g=548.512\n",
            ">638, c1=-608.075, c2=-549.078 g=549.671\n",
            ">639, c1=-609.017, c2=-550.244 g=550.932\n",
            ">640, c1=-610.053, c2=-551.443 g=552.180\n",
            ">641, c1=-611.949, c2=-552.713 g=553.344\n",
            ">642, c1=-613.201, c2=-553.844 g=554.460\n",
            ">643, c1=-614.831, c2=-554.993 g=555.636\n",
            ">644, c1=-616.784, c2=-555.805 g=556.680\n",
            ">645, c1=-616.912, c2=-556.514 g=557.896\n",
            ">646, c1=-616.818, c2=-556.408 g=558.900\n",
            ">647, c1=-619.782, c2=-556.940 g=560.348\n",
            ">648, c1=-620.747, c2=-559.506 g=561.477\n",
            ">649, c1=-621.289, c2=-561.459 g=562.732\n",
            ">650, c1=-622.429, c2=-562.428 g=563.847\n",
            ">651, c1=-624.577, c2=-564.223 g=565.071\n",
            ">652, c1=-625.670, c2=-565.502 g=566.239\n",
            ">653, c1=-626.735, c2=-566.830 g=567.609\n",
            ">654, c1=-628.559, c2=-568.057 g=568.813\n",
            ">655, c1=-630.522, c2=-569.128 g=569.893\n",
            ">656, c1=-630.914, c2=-570.491 g=571.146\n",
            ">657, c1=-632.638, c2=-571.702 g=572.472\n",
            ">658, c1=-633.831, c2=-573.036 g=573.631\n",
            ">659, c1=-636.326, c2=-574.067 g=574.928\n",
            ">660, c1=-636.118, c2=-575.510 g=576.119\n",
            ">661, c1=-638.120, c2=-576.693 g=577.461\n",
            ">662, c1=-640.404, c2=-577.890 g=578.605\n",
            ">663, c1=-641.614, c2=-579.103 g=579.777\n",
            ">664, c1=-642.208, c2=-580.076 g=581.029\n",
            ">665, c1=-644.188, c2=-581.366 g=582.315\n",
            ">666, c1=-644.001, c2=-582.434 g=583.473\n",
            ">667, c1=-646.103, c2=-583.581 g=584.682\n",
            ">668, c1=-647.227, c2=-584.628 g=585.802\n",
            ">669, c1=-648.595, c2=-584.958 g=586.893\n",
            ">670, c1=-651.641, c2=-586.125 g=588.145\n",
            ">671, c1=-651.923, c2=-587.164 g=589.086\n",
            ">672, c1=-653.364, c2=-588.321 g=590.371\n",
            ">673, c1=-654.987, c2=-589.220 g=591.653\n",
            ">674, c1=-654.429, c2=-589.284 g=592.740\n",
            ">675, c1=-658.028, c2=-591.718 g=593.972\n",
            ">676, c1=-658.634, c2=-593.822 g=595.214\n",
            ">677, c1=-660.051, c2=-594.757 g=596.618\n",
            ">678, c1=-660.906, c2=-596.765 g=597.917\n",
            ">679, c1=-663.225, c2=-597.783 g=599.298\n",
            ">Saved: generated_plot_0679.png and model_0679.h5\n",
            ">680, c1=-663.329, c2=-599.077 g=600.317\n",
            ">681, c1=-666.673, c2=-600.123 g=601.642\n",
            ">682, c1=-666.462, c2=-601.349 g=602.657\n",
            ">683, c1=-668.603, c2=-602.415 g=603.893\n",
            ">684, c1=-668.898, c2=-603.015 g=605.037\n",
            ">685, c1=-670.720, c2=-604.340 g=606.472\n",
            ">686, c1=-671.112, c2=-605.340 g=607.337\n",
            ">687, c1=-673.015, c2=-606.803 g=608.757\n",
            ">688, c1=-675.581, c2=-607.706 g=609.755\n",
            ">689, c1=-677.774, c2=-608.140 g=610.872\n",
            ">690, c1=-677.173, c2=-608.974 g=611.875\n",
            ">691, c1=-678.182, c2=-609.637 g=612.429\n",
            ">692, c1=-678.499, c2=-609.413 g=613.383\n",
            ">693, c1=-681.953, c2=-607.143 g=613.826\n",
            ">694, c1=-682.825, c2=-605.837 g=614.666\n",
            ">695, c1=-682.521, c2=-604.259 g=615.143\n",
            ">696, c1=-684.127, c2=-601.624 g=615.362\n",
            ">697, c1=-685.263, c2=-597.089 g=616.172\n",
            ">698, c1=-683.278, c2=-590.773 g=616.600\n",
            ">699, c1=-683.263, c2=-594.769 g=615.831\n",
            ">700, c1=-685.454, c2=-576.310 g=614.734\n",
            ">701, c1=-682.641, c2=-569.183 g=615.738\n",
            ">702, c1=-683.216, c2=-568.696 g=613.272\n",
            ">703, c1=-680.852, c2=-555.750 g=612.671\n",
            ">704, c1=-680.311, c2=-547.619 g=610.525\n",
            ">705, c1=-679.757, c2=-552.154 g=610.688\n",
            ">706, c1=-680.670, c2=-547.839 g=609.490\n",
            ">707, c1=-678.344, c2=-551.335 g=609.232\n",
            ">708, c1=-680.201, c2=-555.610 g=608.208\n",
            ">709, c1=-678.637, c2=-560.975 g=607.965\n",
            ">710, c1=-679.840, c2=-555.273 g=606.431\n",
            ">711, c1=-680.337, c2=-580.593 g=610.532\n",
            ">712, c1=-680.802, c2=-582.317 g=611.864\n",
            ">713, c1=-684.982, c2=-582.914 g=611.939\n",
            ">714, c1=-685.668, c2=-591.032 g=614.784\n",
            ">715, c1=-685.007, c2=-585.152 g=614.624\n",
            ">716, c1=-687.845, c2=-580.633 g=616.553\n",
            ">717, c1=-685.452, c2=-582.745 g=616.605\n",
            ">718, c1=-688.178, c2=-587.420 g=617.719\n",
            ">719, c1=-689.018, c2=-575.121 g=616.586\n",
            ">720, c1=-688.048, c2=-560.109 g=611.473\n",
            ">721, c1=-683.331, c2=-525.227 g=604.850\n",
            ">722, c1=-677.883, c2=-522.689 g=597.064\n",
            ">723, c1=-676.500, c2=-493.772 g=588.223\n",
            ">724, c1=-672.161, c2=-499.467 g=577.912\n",
            ">725, c1=-672.762, c2=-497.729 g=566.121\n",
            ">726, c1=-674.752, c2=-494.257 g=557.299\n",
            ">727, c1=-673.577, c2=-502.716 g=556.062\n",
            ">728, c1=-677.457, c2=-507.697 g=555.240\n",
            ">729, c1=-679.374, c2=-512.180 g=556.203\n",
            ">730, c1=-681.709, c2=-515.866 g=558.124\n",
            ">731, c1=-683.248, c2=-516.786 g=557.062\n",
            ">732, c1=-687.010, c2=-520.786 g=559.872\n",
            ">733, c1=-686.882, c2=-521.181 g=561.297\n",
            ">734, c1=-690.040, c2=-528.334 g=559.931\n",
            ">735, c1=-688.915, c2=-531.362 g=562.667\n",
            ">736, c1=-693.346, c2=-543.244 g=565.008\n",
            ">737, c1=-696.510, c2=-546.865 g=565.696\n",
            ">738, c1=-697.712, c2=-551.115 g=568.749\n",
            ">739, c1=-698.159, c2=-560.472 g=573.762\n",
            ">740, c1=-699.973, c2=-566.056 g=576.468\n",
            ">741, c1=-700.531, c2=-563.798 g=579.134\n",
            ">742, c1=-701.709, c2=-568.393 g=583.525\n",
            ">743, c1=-704.209, c2=-575.409 g=588.675\n",
            ">744, c1=-702.140, c2=-575.006 g=594.378\n",
            ">745, c1=-700.833, c2=-579.584 g=596.380\n",
            ">746, c1=-705.417, c2=-587.216 g=598.753\n",
            ">747, c1=-705.244, c2=-591.680 g=606.590\n",
            ">748, c1=-706.432, c2=-598.608 g=608.622\n",
            ">749, c1=-710.175, c2=-604.143 g=615.651\n",
            ">750, c1=-712.044, c2=-608.022 g=617.915\n",
            ">751, c1=-713.534, c2=-613.063 g=622.481\n",
            ">752, c1=-716.938, c2=-616.989 g=624.298\n",
            ">753, c1=-719.143, c2=-619.972 g=628.484\n",
            ">754, c1=-720.851, c2=-624.957 g=634.497\n",
            ">755, c1=-720.779, c2=-627.730 g=637.087\n",
            ">756, c1=-724.384, c2=-631.926 g=637.775\n",
            ">757, c1=-725.040, c2=-632.942 g=644.794\n",
            ">758, c1=-726.590, c2=-633.218 g=643.542\n",
            ">759, c1=-727.385, c2=-632.566 g=646.700\n",
            ">760, c1=-728.454, c2=-636.511 g=646.485\n",
            ">761, c1=-730.301, c2=-637.100 g=653.969\n",
            ">762, c1=-729.891, c2=-640.494 g=654.163\n",
            ">763, c1=-733.197, c2=-641.900 g=658.175\n",
            ">764, c1=-735.845, c2=-638.135 g=656.058\n",
            ">765, c1=-734.108, c2=-637.275 g=655.456\n",
            ">766, c1=-735.895, c2=-640.013 g=659.226\n",
            ">767, c1=-741.558, c2=-639.968 g=658.958\n",
            ">768, c1=-738.982, c2=-648.306 g=661.935\n",
            ">769, c1=-740.756, c2=-653.577 g=666.622\n",
            ">770, c1=-744.005, c2=-654.529 g=666.380\n",
            ">771, c1=-746.739, c2=-654.417 g=667.600\n",
            ">772, c1=-749.464, c2=-664.702 g=672.442\n",
            ">773, c1=-751.900, c2=-662.055 g=673.630\n",
            ">774, c1=-755.587, c2=-667.346 g=677.678\n",
            ">775, c1=-756.771, c2=-669.891 g=682.828\n",
            ">776, c1=-757.999, c2=-669.898 g=681.498\n",
            ">Saved: generated_plot_0776.png and model_0776.h5\n",
            ">777, c1=-761.463, c2=-676.839 g=687.033\n",
            ">778, c1=-762.690, c2=-675.650 g=685.880\n",
            ">779, c1=-766.983, c2=-681.406 g=687.974\n",
            ">780, c1=-768.879, c2=-684.345 g=690.871\n",
            ">781, c1=-770.906, c2=-685.115 g=695.302\n",
            ">782, c1=-773.004, c2=-686.496 g=692.765\n",
            ">783, c1=-774.521, c2=-688.661 g=697.444\n",
            ">784, c1=-776.927, c2=-692.022 g=701.571\n",
            ">785, c1=-779.763, c2=-695.889 g=701.525\n",
            ">786, c1=-779.937, c2=-693.544 g=705.196\n",
            ">787, c1=-785.015, c2=-698.454 g=704.434\n",
            ">788, c1=-787.378, c2=-703.616 g=709.357\n",
            ">789, c1=-787.045, c2=-700.608 g=711.111\n",
            ">790, c1=-790.410, c2=-699.000 g=709.518\n",
            ">791, c1=-790.476, c2=-698.335 g=713.259\n",
            ">792, c1=-792.795, c2=-695.844 g=711.577\n",
            ">793, c1=-793.327, c2=-695.846 g=711.682\n",
            ">794, c1=-795.443, c2=-699.559 g=712.025\n",
            ">795, c1=-795.966, c2=-698.521 g=713.656\n",
            ">796, c1=-796.777, c2=-683.312 g=711.447\n",
            ">797, c1=-797.225, c2=-699.810 g=716.113\n",
            ">798, c1=-797.552, c2=-706.089 g=715.846\n",
            ">799, c1=-802.248, c2=-703.339 g=718.679\n",
            ">800, c1=-802.945, c2=-708.816 g=720.535\n",
            ">801, c1=-804.735, c2=-714.344 g=720.982\n",
            ">802, c1=-808.253, c2=-720.320 g=725.975\n",
            ">803, c1=-810.566, c2=-726.614 g=729.606\n",
            ">804, c1=-812.442, c2=-729.727 g=731.825\n",
            ">805, c1=-816.705, c2=-731.424 g=735.370\n",
            ">806, c1=-818.943, c2=-733.826 g=739.865\n",
            ">807, c1=-821.545, c2=-735.237 g=740.048\n",
            ">808, c1=-822.148, c2=-737.986 g=743.176\n",
            ">809, c1=-825.191, c2=-741.887 g=746.243\n",
            ">810, c1=-828.193, c2=-742.380 g=744.628\n",
            ">811, c1=-828.798, c2=-743.594 g=749.322\n",
            ">812, c1=-831.240, c2=-744.204 g=751.261\n",
            ">813, c1=-832.726, c2=-745.673 g=751.720\n",
            ">814, c1=-833.866, c2=-741.130 g=749.274\n",
            ">815, c1=-834.887, c2=-741.695 g=747.676\n",
            ">816, c1=-835.635, c2=-740.279 g=750.863\n",
            ">817, c1=-837.888, c2=-736.466 g=749.402\n",
            ">818, c1=-836.762, c2=-734.671 g=752.922\n",
            ">819, c1=-840.315, c2=-741.337 g=753.108\n",
            ">820, c1=-839.824, c2=-727.745 g=746.588\n",
            ">821, c1=-839.937, c2=-738.491 g=752.878\n",
            ">822, c1=-841.738, c2=-734.716 g=753.826\n",
            ">823, c1=-842.066, c2=-736.724 g=750.228\n",
            ">824, c1=-844.952, c2=-736.915 g=754.272\n",
            ">825, c1=-844.345, c2=-740.486 g=757.384\n",
            ">826, c1=-847.469, c2=-745.049 g=758.709\n",
            ">827, c1=-848.848, c2=-751.115 g=760.463\n",
            ">828, c1=-849.024, c2=-748.761 g=760.869\n",
            ">829, c1=-851.969, c2=-756.437 g=763.456\n",
            ">830, c1=-854.802, c2=-759.203 g=766.130\n",
            ">831, c1=-856.393, c2=-760.812 g=769.363\n",
            ">832, c1=-857.507, c2=-766.600 g=772.738\n",
            ">833, c1=-859.477, c2=-764.732 g=773.177\n",
            ">834, c1=-863.526, c2=-762.736 g=774.605\n",
            ">835, c1=-864.956, c2=-765.605 g=775.215\n",
            ">836, c1=-865.634, c2=-767.955 g=777.934\n",
            ">837, c1=-867.557, c2=-767.452 g=778.242\n",
            ">838, c1=-868.856, c2=-770.251 g=776.215\n",
            ">839, c1=-870.691, c2=-772.643 g=780.816\n",
            ">840, c1=-873.435, c2=-775.148 g=782.246\n",
            ">841, c1=-874.363, c2=-778.257 g=784.557\n",
            ">842, c1=-876.576, c2=-780.014 g=788.268\n",
            ">843, c1=-879.249, c2=-780.647 g=790.055\n",
            ">844, c1=-880.676, c2=-781.237 g=789.894\n",
            ">845, c1=-881.321, c2=-777.108 g=786.549\n",
            ">846, c1=-881.591, c2=-772.751 g=786.682\n",
            ">847, c1=-882.619, c2=-781.057 g=791.109\n",
            ">848, c1=-885.178, c2=-776.726 g=790.326\n",
            ">849, c1=-886.810, c2=-780.111 g=793.169\n",
            ">850, c1=-886.492, c2=-776.098 g=791.534\n",
            ">851, c1=-887.906, c2=-768.935 g=790.828\n",
            ">852, c1=-888.679, c2=-769.533 g=787.673\n",
            ">853, c1=-890.527, c2=-764.179 g=788.181\n",
            ">854, c1=-888.310, c2=-765.613 g=787.805\n",
            ">855, c1=-891.200, c2=-761.040 g=785.480\n",
            ">856, c1=-889.564, c2=-763.740 g=784.488\n",
            ">857, c1=-890.521, c2=-758.617 g=783.007\n",
            ">858, c1=-890.749, c2=-757.766 g=781.694\n",
            ">859, c1=-891.395, c2=-750.480 g=779.640\n",
            ">860, c1=-891.217, c2=-756.430 g=778.103\n",
            ">861, c1=-890.926, c2=-752.741 g=778.274\n",
            ">862, c1=-891.656, c2=-747.880 g=775.284\n",
            ">863, c1=-892.484, c2=-745.634 g=769.781\n",
            ">864, c1=-890.877, c2=-721.922 g=756.967\n",
            ">865, c1=-890.242, c2=-690.396 g=733.075\n",
            ">866, c1=-889.210, c2=-674.883 g=717.233\n",
            ">867, c1=-888.958, c2=-670.275 g=695.982\n",
            ">868, c1=-887.176, c2=-665.942 g=687.443\n",
            ">869, c1=-888.987, c2=-671.060 g=688.490\n",
            ">870, c1=-893.013, c2=-685.880 g=689.434\n",
            ">871, c1=-894.530, c2=-699.988 g=696.717\n",
            ">872, c1=-896.680, c2=-705.769 g=703.441\n",
            ">873, c1=-896.085, c2=-715.774 g=710.045\n",
            ">Saved: generated_plot_0873.png and model_0873.h5\n",
            ">874, c1=-899.806, c2=-723.203 g=714.382\n",
            ">875, c1=-899.854, c2=-729.584 g=714.951\n",
            ">876, c1=-901.752, c2=-732.837 g=720.333\n",
            ">877, c1=-901.199, c2=-738.269 g=718.610\n",
            ">878, c1=-904.279, c2=-743.620 g=716.584\n",
            ">879, c1=-902.390, c2=-745.587 g=712.987\n",
            ">880, c1=-901.832, c2=-743.396 g=696.060\n",
            ">881, c1=-900.146, c2=-735.392 g=675.598\n",
            ">882, c1=-896.411, c2=-707.951 g=654.616\n",
            ">883, c1=-890.606, c2=-696.168 g=599.128\n",
            ">884, c1=-882.063, c2=-646.222 g=566.651\n",
            ">885, c1=-870.291, c2=-611.938 g=527.051\n",
            ">886, c1=-867.792, c2=-611.685 g=482.112\n",
            ">887, c1=-857.077, c2=-603.153 g=502.638\n",
            ">888, c1=-853.810, c2=-595.133 g=484.195\n",
            ">889, c1=-854.905, c2=-616.267 g=488.982\n",
            ">890, c1=-854.940, c2=-617.977 g=456.522\n",
            ">891, c1=-857.446, c2=-621.949 g=446.588\n",
            ">892, c1=-859.397, c2=-613.272 g=461.719\n",
            ">893, c1=-858.573, c2=-633.212 g=443.285\n",
            ">894, c1=-860.862, c2=-652.066 g=425.927\n",
            ">895, c1=-867.278, c2=-674.978 g=394.584\n",
            ">896, c1=-869.282, c2=-683.718 g=383.041\n",
            ">897, c1=-874.515, c2=-696.171 g=341.774\n",
            ">898, c1=-874.042, c2=-703.395 g=337.551\n",
            ">899, c1=-875.744, c2=-713.603 g=339.640\n",
            ">900, c1=-878.075, c2=-719.518 g=357.558\n",
            ">901, c1=-877.294, c2=-731.339 g=366.815\n",
            ">902, c1=-883.696, c2=-737.304 g=360.685\n",
            ">903, c1=-883.977, c2=-728.170 g=417.314\n",
            ">904, c1=-884.172, c2=-737.627 g=417.545\n",
            ">905, c1=-885.495, c2=-737.118 g=405.664\n",
            ">906, c1=-887.334, c2=-727.508 g=407.019\n",
            ">907, c1=-883.904, c2=-716.764 g=446.129\n",
            ">908, c1=-886.848, c2=-728.130 g=480.367\n",
            ">909, c1=-884.474, c2=-730.006 g=528.706\n",
            ">910, c1=-882.714, c2=-740.425 g=506.103\n",
            ">911, c1=-883.130, c2=-720.922 g=467.917\n",
            ">912, c1=-879.178, c2=-697.390 g=365.072\n",
            ">913, c1=-874.710, c2=-615.293 g=170.014\n",
            ">914, c1=-856.135, c2=-447.813 g=-64.652\n",
            ">915, c1=-825.587, c2=-205.323 g=-219.558\n",
            ">916, c1=-782.483, c2=-105.239 g=-340.669\n",
            ">917, c1=-737.428, c2=-84.414 g=-338.432\n",
            ">918, c1=-691.749, c2=-60.575 g=-313.304\n",
            ">919, c1=-655.437, c2=-54.575 g=-204.950\n",
            ">920, c1=-608.936, c2=-100.725 g=-144.416\n",
            ">921, c1=-571.798, c2=-115.532 g=-64.460\n",
            ">922, c1=-547.213, c2=-128.459 g=16.110\n",
            ">923, c1=-541.013, c2=-125.434 g=89.477\n",
            ">924, c1=-507.653, c2=-113.825 g=139.713\n",
            ">925, c1=-490.123, c2=-115.259 g=160.446\n",
            ">926, c1=-473.984, c2=-79.728 g=214.673\n",
            ">927, c1=-481.509, c2=-58.350 g=188.088\n",
            ">928, c1=-493.551, c2=23.174 g=146.241\n",
            ">929, c1=-496.917, c2=54.772 g=68.311\n",
            ">930, c1=-527.200, c2=52.280 g=-7.424\n",
            ">931, c1=-548.441, c2=21.378 g=-58.231\n",
            ">932, c1=-558.430, c2=-20.292 g=-107.609\n",
            ">933, c1=-564.691, c2=-57.242 g=-204.813\n",
            ">934, c1=-583.721, c2=-126.458 g=-328.309\n",
            ">935, c1=-593.036, c2=-143.055 g=-389.389\n",
            ">936, c1=-595.337, c2=-83.472 g=-414.711\n",
            ">937, c1=-578.132, c2=-118.592 g=-442.598\n",
            ">938, c1=-589.493, c2=-81.513 g=-437.124\n",
            ">939, c1=-566.095, c2=-135.649 g=-468.423\n",
            ">940, c1=-554.436, c2=-47.977 g=-447.668\n",
            ">941, c1=-535.772, c2=-55.295 g=-448.454\n",
            ">942, c1=-544.711, c2=-115.807 g=-465.277\n",
            ">943, c1=-535.968, c2=46.076 g=-408.546\n",
            ">944, c1=-531.468, c2=18.851 g=-391.698\n",
            ">945, c1=-501.521, c2=36.007 g=-391.347\n",
            ">946, c1=-514.102, c2=88.636 g=-343.505\n",
            ">947, c1=-504.615, c2=97.630 g=-317.339\n",
            ">948, c1=-490.662, c2=129.219 g=-267.146\n",
            ">949, c1=-483.360, c2=127.383 g=-197.692\n",
            ">950, c1=-483.299, c2=122.171 g=-143.416\n",
            ">951, c1=-484.553, c2=118.409 g=-132.701\n",
            ">952, c1=-474.564, c2=92.690 g=-138.996\n",
            ">953, c1=-469.231, c2=104.233 g=-141.322\n",
            ">954, c1=-482.276, c2=83.073 g=-169.285\n",
            ">955, c1=-484.138, c2=54.783 g=-204.634\n",
            ">956, c1=-479.136, c2=81.502 g=-202.745\n",
            ">957, c1=-477.767, c2=48.522 g=-258.913\n",
            ">958, c1=-480.792, c2=18.694 g=-288.334\n",
            ">959, c1=-492.096, c2=-5.019 g=-337.531\n",
            ">960, c1=-472.447, c2=167.608 g=-269.056\n",
            ">961, c1=-490.595, c2=48.539 g=-314.857\n",
            ">962, c1=-461.151, c2=68.543 g=-340.212\n",
            ">963, c1=-497.880, c2=83.083 g=-326.696\n",
            ">964, c1=-464.167, c2=44.284 g=-374.278\n",
            ">965, c1=-506.363, c2=88.615 g=-353.877\n",
            ">966, c1=-458.215, c2=0.435 g=-433.279\n",
            ">967, c1=-478.115, c2=40.276 g=-409.673\n",
            ">968, c1=-486.717, c2=27.238 g=-427.561\n",
            ">969, c1=-443.911, c2=31.145 g=-432.925\n",
            ">970, c1=-462.409, c2=20.862 g=-445.978\n",
            ">Saved: generated_plot_0970.png and model_0970.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYvaXwIILepy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}